{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in the answers\n",
    "\n",
    "df_answers = pd.read_csv('reddit_answers_big.csv', sep = \";\")\n",
    "df_answers.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grabbing the top answers\n",
    "\n",
    "df_top_votes = df_answers.groupby('q_id')['votes'].idxmax()\n",
    "df_top_answers = df_answers.loc[df_top_votes]\n",
    "\n",
    "df_top_answers.rename(columns = {'text': 'answer'}, inplace = True)\n",
    "df_top_answers.rename(columns = {'q_id': 'id'}, inplace = True)\n",
    "df_top_answers.rename(columns = {'votes': 'answer_votes'}, inplace = True)\n",
    "\n",
    "df_top_answers.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in the questions\n",
    "\n",
    "df_questions = pd.read_csv('reddit_questions_big.csv', sep = \";\")\n",
    "\n",
    "# renaming columns\n",
    "df_questions.rename(columns = {'text': 'question'}, inplace = True)\n",
    "df_questions.rename(columns = {'votes': 'question_votes'}, inplace = True)\n",
    "\n",
    "df_questions.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining questions and answers on id\n",
    "\n",
    "merged_df = df_questions.merge(df_top_answers, on = 'id')\n",
    "\n",
    "merged_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning data\n",
    "\n",
    "merged_df.drop(['timestamp', 'date', 'Unnamed: 0'], axis = 1, inplace = True)\n",
    "\n",
    "merged_df = merged_df.reindex(columns = ['id', 'question', 'answer', 'question_votes' 'answer_votes'])\n",
    "\n",
    "merged_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsizing the data\n",
    "merged_df = merged_df.sort_values(by = 'answer_votes', ascending = False)\n",
    "merged_df_1k = merged_df[:1000]\n",
    "merged_df_1k.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine tuning format\n",
    "questions, answers = merged_df_1k['question'], merged_df_1k['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_openai_format = [{'messages': [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot and reddit expert who likes to answer with bullets\"},\n",
    "                                  {\"role\": \"user\", \"content\": q},\n",
    "                                  {\"role\": \"assistant\", \"content\": a}]} for q, a in zip(questions, answers)]\n",
    "\n",
    "qa_openai_format[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"training_data.jsonl\", \"w\") as f:\n",
    "    for entry in qa_openai_format:\n",
    "        f.write(json.dumps(entry))\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "data_path = \"training_data.jsonl\"\n",
    "\n",
    "# load the dataset\n",
    "with open(data_path, 'r', encoding = 'utf-8') as f:\n",
    "    dataset = [json.loads(line) for line in f]\n",
    "\n",
    "\n",
    "# Format error checks\n",
    "format_errors = defaultdict(int)\n",
    "\n",
    "for ex in dataset:\n",
    "    if not isinstance(ex, dict):\n",
    "        format_errors[\"data_type\"] += 1\n",
    "        continue\n",
    "        \n",
    "    messages = ex.get(\"messages\", None)\n",
    "    if not messages:\n",
    "        format_errors[\"missing_messages_list\"] += 1\n",
    "        continue\n",
    "        \n",
    "    for message in messages:\n",
    "        if \"role\" not in message or \"content\" not in message:\n",
    "            format_errors[\"message_missing_key\"] += 1\n",
    "        \n",
    "        if any(k not in (\"role\", \"content\", \"name\", \"function_call\", \"weight\") for k in message):\n",
    "            format_errors[\"message_unrecognized_key\"] += 1\n",
    "        \n",
    "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
    "            format_errors[\"unrecognized_role\"] += 1\n",
    "            \n",
    "        content = message.get(\"content\", None)\n",
    "        function_call = message.get(\"function_call\", None)\n",
    "        \n",
    "        if (not content and not function_call) or not isinstance(content, str):\n",
    "            format_errors[\"missing_content\"] += 1\n",
    "    \n",
    "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "        format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "if format_errors:\n",
    "    print(\"Found errors:\")\n",
    "    for k, v in format_errors.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "else:\n",
    "    print(\"No errors found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install openai\n",
    "import os\n",
    "import openai\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"YOUR KEY GOES HERE\"\n",
    "# openai.api_key=os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to finally start fine tuning (sending the training data to OpenAI)\n",
    "\n",
    "client.files.create(\n",
    "    file = open(\"training_data.jsonl\", 'rb'),\n",
    "    purpose = 'fine-tune'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.fine_tuning.jobs.create(\n",
    "    training_file = 'file id outputted from last code block',\n",
    "    model = 'gpt-3.5-turbo'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.fine_tuning.jobs.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after training\n",
    "\n",
    "system_prompt = \"Marv is a factual chatbot and reddit expert who likes to answer with bullets\"\n",
    "user_question = \"Give me the dumbest thing you've ever done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.creatte(\n",
    "    model = \"trained model (ft:gpt-3.5)\",\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': system_prompt},\n",
    "        {'role': 'user', 'content': user_question}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
